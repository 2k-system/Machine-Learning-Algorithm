{
 "cells": [
  {
   "cell_type": "raw",
   "id": "d8086c82-04fa-41b4-be53-f3e7139317b7",
   "metadata": {},
   "source": [
    "Importing required library"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f98f8811-7762-4450-a6b0-75e3c84303c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from collections import Counter"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6a794eb9-57b3-4d54-ab84-1415ffd8b814",
   "metadata": {},
   "source": [
    "## Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "c17bbaa0-27e7-486c-8a12-aa969527d4c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "class LogisticRegression():\n",
    "    def __init__(self, lr, n_iter):\n",
    "        if lr <= 0:\n",
    "            raise ValueError(\"Learning rate must be positive.\")\n",
    "        if n_iter <= 0 or not isinstance(n_iter, int):\n",
    "            raise ValueError(\"Number of iterations must be a positive integer.\")\n",
    "        \n",
    "        self.lr = lr\n",
    "        self.n_iter = n_iter\n",
    "        self.weights = None\n",
    "        self.bias = None\n",
    "\n",
    "    def sigmoid(self, r):\n",
    "        return 1 / (1 + np.exp(-r))\n",
    "\n",
    "    def fit_model(self, X, y):\n",
    "        # Check if X and y are numpy arrays\n",
    "        if not isinstance(X, np.ndarray):\n",
    "            raise ValueError(\"Input features X must be a numpy array.\")\n",
    "        if not isinstance(y, np.ndarray):\n",
    "            raise ValueError(\"Target variable y must be a numpy array.\")\n",
    "        \n",
    "        # Check if X and y dimensions match\n",
    "        if X.shape[0] != y.shape[0]:\n",
    "            raise ValueError(f\"Number of samples in X ({X.shape[0]}) does not match length of y ({y.shape[0]}).\")\n",
    "        \n",
    "        # Initialize weights and bias\n",
    "        n_samples, n_features = X.shape\n",
    "        self.weights = np.random.rand(n_features)\n",
    "        self.bias = 0\n",
    "\n",
    "        # Start training iterations\n",
    "        for _ in range(self.n_iter):\n",
    "            linear_output = np.dot(X, self.weights) + self.bias\n",
    "            y_pred = self.sigmoid(linear_output)\n",
    "\n",
    "            # Compute gradients\n",
    "            delw = (1/n_samples) * np.dot(X.T, (y_pred - y))\n",
    "            delb = (1/n_samples) * np.sum(y_pred - y)\n",
    "\n",
    "            # Update weights and bias\n",
    "            self.weights -= self.lr * delw\n",
    "            self.bias -= self.lr * delb\n",
    "\n",
    "    def predict_class(self, X):\n",
    "        if not isinstance(X, np.ndarray):\n",
    "            raise ValueError(\"Input features X must be a numpy array.\")\n",
    "        if X.shape[1] != self.weights.shape[0]:\n",
    "            raise ValueError(f\"Number of features in X ({X.shape[1]}) does not match the number of features in the model ({self.weights.shape[0]}).\")\n",
    "        \n",
    "        linear_output = np.dot(X, self.weights) + self.bias\n",
    "        y_pred = self.sigmoid(linear_output)\n",
    "        y_pred_class = [1 if i > 0.5 else 0 for i in y_pred]\n",
    "        return y_pred_class"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cd26ac2f-53b0-4023-84d9-daf82488cd86",
   "metadata": {},
   "source": [
    "## Naive Bayes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "84f5ab79-c9fa-458d-a025-0592b3cfd104",
   "metadata": {},
   "outputs": [],
   "source": [
    "class NaiveBayes:\n",
    "    def __init__(self):\n",
    "        self.class_probs = None  \n",
    "        self.mean = None \n",
    "        self.var = None \n",
    "        self.classes = None  \n",
    "\n",
    "    def fit(self, X, y):\n",
    "        if not isinstance(X, np.ndarray):\n",
    "            raise ValueError(\"Input features X must be a numpy array.\")\n",
    "        if not isinstance(y, np.ndarray):\n",
    "            raise ValueError(\"Target variable y must be a numpy array.\")\n",
    "        \n",
    "        if X.shape[0] != y.shape[0]:\n",
    "            raise ValueError(f\"Number of samples in X ({X.shape[0]}) does not match length of y ({y.shape[0]}).\")\n",
    "        \n",
    "        self.classes = np.unique(y)\n",
    "        if len(self.classes) < 2:\n",
    "            raise ValueError(\"The target variable y must have at least two classes.\")\n",
    "\n",
    "        n_samples, n_features = X.shape\n",
    "\n",
    "        self.mean = np.zeros((len(self.classes), n_features))\n",
    "        self.var = np.zeros((len(self.classes), n_features))\n",
    "        self.class_probs = np.zeros(len(self.classes))\n",
    "\n",
    "        for i, label in enumerate(self.classes):\n",
    "            X_class = X[y == label]\n",
    "            self.mean[i, :] = X_class.mean(axis=0)\n",
    "            self.var[i, :] = X_class.var(axis=0)\n",
    "            self.class_probs[i] = X_class.shape[0] / n_samples\n",
    "\n",
    "    def predict(self, X):\n",
    "        # Check if X is a numpy array\n",
    "        if not isinstance(X, np.ndarray):\n",
    "            raise ValueError(\"Input features X must be a numpy array.\")\n",
    "        if X.shape[1] != self.mean.shape[1]:\n",
    "            raise ValueError(f\"Number of features in X ({X.shape[1]}) does not match the number of features in the model ({self.mean.shape[1]}).\")\n",
    "\n",
    "        predictions = [self._predict_sample(sample) for sample in X]\n",
    "        return np.array(predictions)\n",
    "\n",
    "    def _predict_sample(self, sample):\n",
    "        posteriors = []\n",
    "        for i, label in enumerate(self.classes):\n",
    "            prior = np.log(self.class_probs[i])\n",
    "            likelihood = np.sum(np.log(self._pdf(i, sample)))\n",
    "            posterior = prior + likelihood\n",
    "            posteriors.append(posterior)\n",
    "        return self.classes[np.argmax(posteriors)]\n",
    "\n",
    "    def _pdf(self, class_idx, sample):\n",
    "        mean = self.mean[class_idx]\n",
    "        var = self.var[class_idx]\n",
    "        var = np.maximum(var, 1e-9)\n",
    "        exponent = np.exp(-((sample - mean) ** 2) / (2 * var))\n",
    "        return (1 / np.sqrt(2 * np.pi * var)) * exponent"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fa710622-baf4-4365-b03e-8f102e7da05a",
   "metadata": {},
   "source": [
    "## K-Nearest Neighbor(KNN)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "898bdc69-0709-4475-bc0e-3b1687aaa0c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "class KNN:\n",
    "    def __init__(self, k=3):\n",
    "        # Validate k\n",
    "        if not isinstance(k, int) or k <= 0:\n",
    "            raise ValueError(\"k must be a positive integer.\")\n",
    "        self.k = k\n",
    "        self.X_train = None\n",
    "        self.y_train = None\n",
    "\n",
    "    def set_k(self, k):\n",
    "        \"\"\"User can dynamically set or update k.\"\"\"\n",
    "        if not isinstance(k, int) or k <= 0:\n",
    "            raise ValueError(\"k must be a positive integer.\")\n",
    "        self.k = k\n",
    "        print(f\"Updated k value to {self.k}\")\n",
    "\n",
    "    def fit(self, X, y):\n",
    "        # Check if X and y are numpy arrays\n",
    "        if not isinstance(X, np.ndarray):\n",
    "            raise ValueError(\"Input features X must be a numpy array.\")\n",
    "        if not isinstance(y, np.ndarray):\n",
    "            raise ValueError(\"Target variable y must be a numpy array.\")\n",
    "        \n",
    "        if X.shape[0] != y.shape[0]:\n",
    "            raise ValueError(f\"Number of samples in X ({X.shape[0]}) does not match length of y ({y.shape[0]}).\")\n",
    "\n",
    "        self.X_train = X\n",
    "        self.y_train = y\n",
    "\n",
    "    def predict(self, X):\n",
    "        if not isinstance(X, np.ndarray):\n",
    "            raise ValueError(\"Input features X must be a numpy array.\")\n",
    "        \n",
    "        # Check if X has the same number of features as the training data\n",
    "        if X.shape[1] != self.X_train.shape[1]:\n",
    "            raise ValueError(f\"Number of features in X ({X.shape[1]}) does not match the number of features in the training data ({self.X_train.shape[1]}).\")\n",
    "        \n",
    "        predictions = [self._predict_sample(sample) for sample in X]\n",
    "        return np.array(predictions)\n",
    "\n",
    "    def _predict_sample(self, sample):\n",
    "        # Calculate the Euclidean distance between the sample and all training points\n",
    "        distances = [self._euclidean_distance(sample, train_sample) for train_sample in self.X_train]\n",
    "        \n",
    "        k_indices = np.argsort(distances)[:self.k]\n",
    "        k_nearest_labels = self.y_train[k_indices]\n",
    "        most_common = Counter(k_nearest_labels).most_common(1)\n",
    "        return most_common[0][0]\n",
    "\n",
    "    def _euclidean_distance(self, point1, point2):\n",
    "        return np.sqrt(np.sum((point1 - point2) ** 2))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f75ee57b-9518-4c1f-8d14-2be960e6f8b9",
   "metadata": {},
   "source": [
    "## Decision Tree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "fc3a6e27-0345-403f-a16f-c7eae172e55c",
   "metadata": {},
   "outputs": [],
   "source": [
    "class DecisionTree:\n",
    "    def __init__(self, max_depth=None, min_samples_split=2):\n",
    "        self.max_depth = max_depth\n",
    "        self.min_samples_split = min_samples_split\n",
    "        self.tree = None\n",
    "    \n",
    "    def fit(self, X, y):\n",
    "        \"\"\"Builds the decision tree based on the training data.\"\"\"\n",
    "        self.tree = self._build_tree(X, y)\n",
    "    \n",
    "    def _build_tree(self, X, y, depth=0):\n",
    "        \"\"\"Recursively builds the decision tree.\"\"\"\n",
    "        # Check if stopping conditions are met\n",
    "        if len(np.unique(y)) == 1:  # Pure node\n",
    "            return {\"label\": np.unique(y)[0]}\n",
    "        \n",
    "        if len(X) < self.min_samples_split:  # If not enough samples to split further\n",
    "            return {\"label\": Counter(y).most_common(1)[0][0]}\n",
    "        \n",
    "        if self.max_depth and depth >= self.max_depth:  # Maximum depth reached\n",
    "            return {\"label\": Counter(y).most_common(1)[0][0]}\n",
    "        \n",
    "        # Find the best split\n",
    "        best_split = self._find_best_split(X, y)\n",
    "        \n",
    "        # Recursively build the left and right branches of the tree\n",
    "        left_tree = self._build_tree(X[best_split[\"left_indices\"]], y[best_split[\"left_indices\"]], depth + 1)\n",
    "        right_tree = self._build_tree(X[best_split[\"right_indices\"]], y[best_split[\"right_indices\"]], depth + 1)\n",
    "        \n",
    "        return {\n",
    "            \"feature\": best_split[\"feature\"],\n",
    "            \"threshold\": best_split[\"threshold\"],\n",
    "            \"left\": left_tree,\n",
    "            \"right\": right_tree\n",
    "        }\n",
    "    \n",
    "    def _find_best_split(self, X, y):\n",
    "        \"\"\"Find the best feature and threshold to split the data.\"\"\"\n",
    "        best_gini = float(\"inf\")\n",
    "        best_split = {}\n",
    "        \n",
    "        n_samples, n_features = X.shape\n",
    "        \n",
    "        # Loop over all features\n",
    "        for feature in range(n_features):\n",
    "            # Get unique values of the feature\n",
    "            possible_thresholds = np.unique(X[:, feature])\n",
    "            \n",
    "            for threshold in possible_thresholds:\n",
    "                # Split the data based on this feature and threshold\n",
    "                left_indices = np.where(X[:, feature] <= threshold)[0]\n",
    "                right_indices = np.where(X[:, feature] > threshold)[0]\n",
    "                \n",
    "                if len(left_indices) == 0 or len(right_indices) == 0:\n",
    "                    continue\n",
    "                \n",
    "                # Calculate Gini impurity for this split\n",
    "                gini = self._gini_impurity(y[left_indices], y[right_indices])\n",
    "                \n",
    "                if gini < best_gini:\n",
    "                    best_gini = gini\n",
    "                    best_split = {\n",
    "                        \"feature\": feature,\n",
    "                        \"threshold\": threshold,\n",
    "                        \"left_indices\": left_indices,\n",
    "                        \"right_indices\": right_indices\n",
    "                    }\n",
    "        \n",
    "        return best_split\n",
    "    \n",
    "    def _gini_impurity(self, left_y, right_y):\n",
    "        \"\"\"Calculate the Gini impurity for a split.\"\"\"\n",
    "        n_left = len(left_y)\n",
    "        n_right = len(right_y)\n",
    "        total = n_left + n_right\n",
    "        \n",
    "        left_gini = 1 - sum((np.sum(left_y == c) / n_left) ** 2 for c in np.unique(left_y))\n",
    "        right_gini = 1 - sum((np.sum(right_y == c) / n_right) ** 2 for c in np.unique(right_y))\n",
    "        \n",
    "        gini = (n_left / total) * left_gini + (n_right / total) * right_gini\n",
    "        return gini\n",
    "    \n",
    "    def predict(self, X):\n",
    "        \"\"\"Predict the class labels for the input samples.\"\"\"\n",
    "        return np.array([self._predict_sample(x, self.tree) for x in X])\n",
    "    \n",
    "    def _predict_sample(self, sample, tree):\n",
    "        \"\"\"Recursively traverse the tree to predict the class label for a sample.\"\"\"\n",
    "        if \"label\" in tree:\n",
    "            return tree[\"label\"]\n",
    "        \n",
    "        feature_value = sample[tree[\"feature\"]]\n",
    "        \n",
    "        if feature_value <= tree[\"threshold\"]:\n",
    "            return self._predict_sample(sample, tree[\"left\"])\n",
    "        else:\n",
    "            return self._predict_sample(sample, tree[\"right\"])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bb08bac9-b2c2-45ed-8e1c-b07b0e88aea6",
   "metadata": {},
   "source": [
    "## Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "1f95e287-08a2-4010-b674-cd628ac4f538",
   "metadata": {},
   "outputs": [],
   "source": [
    "class RandomForest:\n",
    "    def __init__(self, n_estimators=100, max_depth=None, min_samples_split=2):\n",
    "        if not isinstance(n_estimators, int) or n_estimators <= 0:\n",
    "            raise ValueError(\"n_estimators must be a positive integer.\")\n",
    "        \n",
    "        if max_depth is not None and (not isinstance(max_depth, int) or max_depth <= 0):\n",
    "            raise ValueError(\"max_depth must be a positive integer or None.\")\n",
    "        \n",
    "        if not isinstance(min_samples_split, int) or min_samples_split <= 0:\n",
    "            raise ValueError(\"min_samples_split must be a positive integer.\")\n",
    "\n",
    "        self.n_estimators = n_estimators\n",
    "        self.max_depth = max_depth\n",
    "        self.min_samples_split = min_samples_split\n",
    "        self.trees = []\n",
    "\n",
    "    def fit(self, X, y):\n",
    "        if not isinstance(X, np.ndarray):\n",
    "            raise ValueError(\"Input features X must be a numpy array.\")\n",
    "        if not isinstance(y, np.ndarray):\n",
    "            raise ValueError(\"Target variable y must be a numpy array.\")\n",
    "        \n",
    "        if X.shape[0] != y.shape[0]:\n",
    "            raise ValueError(f\"Number of samples in X ({X.shape[0]}) does not match length of y ({y.shape[0]}).\")\n",
    "        \n",
    "        if X.shape[0] == 0 or X.shape[1] == 0:\n",
    "            raise ValueError(\"Input data X cannot be empty.\")\n",
    "        for _ in range(self.n_estimators):\n",
    "            X_sample, y_sample = resample(X, y, n_samples=X.shape[0])\n",
    "            \n",
    "            tree = DecisionTree(max_depth=self.max_depth, min_samples_split=self.min_samples_split)\n",
    "            tree.fit(X_sample, y_sample)\n",
    "            \n",
    "            self.trees.append(tree)\n",
    "\n",
    "    def predict(self, X):\n",
    "        if not isinstance(X, np.ndarray):\n",
    "            raise ValueError(\"Input features X must be a numpy array.\")\n",
    "        \n",
    "        predictions = np.array([self._predict_sample(sample) for sample in X])\n",
    "        return predictions\n",
    "\n",
    "    def _predict_sample(self, sample):\n",
    "        tree_predictions = [tree.predict([sample])[0] for tree in self.trees]\n",
    "        most_common = Counter(tree_predictions).most_common(1)\n",
    "        return most_common[0][0]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5a50dd63-8596-4a16-87ee-de5cc1d867e4",
   "metadata": {},
   "source": [
    "## Support Vector Machine(SVM)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "3d0e09e8-d5ef-4b85-b726-d2883aff27b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "class SVM():\n",
    "    def __init__(self, lr, n_iter, C):\n",
    "        if lr <= 0:\n",
    "            raise ValueError(\"Learning rate must be positive.\")\n",
    "        if n_iter <= 0 or not isinstance(n_iter, int):\n",
    "            raise ValueError(\"Number of iterations must be a positive integer.\")\n",
    "        if C <= 0:\n",
    "            raise ValueError(\"Regularization parameter C must be positive.\")\n",
    "        \n",
    "        self.lr = lr\n",
    "        self.n_iter = n_iter\n",
    "        self.C = C\n",
    "        self.weights = None\n",
    "        self.bias = None\n",
    "\n",
    "    def hinge_loss(self, X, y):\n",
    "        return np.maximum(0, 1 - y * (np.dot(X, self.weights) + self.bias))\n",
    "    \n",
    "    def fit(self, X, y):\n",
    "        # Check if X and y are numpy arrays\n",
    "        if not isinstance(X, np.ndarray):\n",
    "            raise ValueError(\"Input features X must be a numpy array.\")\n",
    "        if not isinstance(y, np.ndarray):\n",
    "            raise ValueError(\"Target variable y must be a numpy array.\")\n",
    "        \n",
    "        # Check if X and y dimensions match\n",
    "        if X.shape[0] != y.shape[0]:\n",
    "            raise ValueError(f\"Number of samples in X ({X.shape[0]}) does not match length of y ({y.shape[0]}).\")\n",
    "        \n",
    "        # Ensure that y has values -1 and 1 (SVM convention)\n",
    "        if not np.all(np.isin(y, [-1, 1])):\n",
    "            raise ValueError(\"Target variable y must contain only -1 and 1 values.\")\n",
    "        \n",
    "        # Initialize weights and bias\n",
    "        n_samples, n_features = X.shape\n",
    "        self.weights = np.random.rand(n_features)\n",
    "        self.bias = 0\n",
    "        \n",
    "        # Start training iterations\n",
    "        for _ in range(self.n_iter):\n",
    "            for i in range(n_samples):\n",
    "                if y[i] * (np.dot(X[i], self.weights) + self.bias) < 1:\n",
    "                    # Update weights and bias if the sample is misclassified\n",
    "                    self.weights -= self.lr * (2 * self.C * self.weights - np.dot(X[i], y[i]))\n",
    "                    self.bias -= self.lr * (-y[i])\n",
    "                else:\n",
    "                    # Regularization term\n",
    "                    self.weights -= self.lr * (2 * self.C * self.weights)\n",
    "\n",
    "    def predict(self, X):\n",
    "        if not isinstance(X, np.ndarray):\n",
    "            raise ValueError(\"Input features X must be a numpy array.\")\n",
    "        if X.shape[1] != self.weights.shape[0]:\n",
    "            raise ValueError(f\"Number of features in X ({X.shape[1]}) does not match the number of features in the model ({self.weights.shape[0]}).\")\n",
    "        \n",
    "        # Make predictions based on sign of decision boundary\n",
    "        linear_output = np.dot(X, self.weights) + self.bias\n",
    "        y_pred = np.sign(linear_output)\n",
    "        return y_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7eaa13ed-af06-4f82-ad2c-e48a8c732660",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a04ec65e-7c18-4fc6-aae8-3961fa96c945",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
